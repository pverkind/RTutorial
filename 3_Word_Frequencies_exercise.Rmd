---
title: "R Tutorial: Word Frequency (continued)"
output: 
  html_document:
      self_contained: false
---

```{r setup, include=FALSE}
tutorial::go_interactive()
```

## Introduction

This exercise is based on Jockers' *Text Analysis with R For Students of Literature*, 
Chapter 3: "Accessing and Comparing Word Frequency Data". In this chapter, he
introduces a number of important concepts in programming with R: 

* **indexing**: accessing values in a vector based on their position or name
* **recycling**: the reuse of values in operations with vectors of different size

Jockers uses Melville's Moby Dick as his main example. Because English behaves
differently from Arabic and Persian, we will use al-Ṭabari's *History* as our
example text. 


## Setting up

We will start the exercise with some code we created in the previous classes,
in which we created a book frequency table of token frequencies.

Create a new R script file in your Jockers folder, and name it "Chapter3_ex_<YOURNAME>.R".
You can use the interactive sessions on this tutorial page to experiment
with the commands, but be sure to write the code in your personal script file
as well. 

Please click the "Run" button below the script to load the example text
(al-Tabari's history), tokenize it and to create a table of word frequencies:

```{r ex="setting-up", type="pre-exercise-code"}
# make sure Arabic is displayed correctly: 
Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
```


```{r ex="setting-up", type="sample-code"}
library("stringr")

url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
splitter_index <- which(text_v == "#META#Header#End#")
lines_v <- text_v[(splitter_index+1):length(text_v)]
book_v <- paste(lines_v, collapse = "\n")
book_word_l <- str_split(book_v, "\\W+")
book_word_v <- unlist(book_word_l)
book_freqs_t <- table(book_word_v)
sorted_book_freqs_t <- sort(book_freqs_t, decreasing = TRUE)
```

You can copy this code into your `Chapter3_ex_<YOURNAME>.R` script file. 

Run the script in RStudio and make sure it executed correctly, by printing
the first value in the `sorted_book_freqs_t` vector. 

## Accessing token frequency data
(Jockers p. 32-33)

We can access the tokens and their frequencies in the sorted frequency table `sorted_book_freqs_t` in two ways: 

* by their position ("index") in the table; this is called "numerical indexing": 

  ```
  > sorted_book_freqs_t[1]  # access the first (that is, most frequent) element in the table
   بن 
  44050 
  ```

* by the tokens  themselves; this is called "named indexing": 

  ```
  > sorted_book_freqs_t["بن"]
   بن 
  44050 
  ```

Note that these two types of indexing are not available for all data types; 
for "atomic" vectors (collections of data that contain only one data type, 
like the `lines_v`, `book_v` and `book_word_v` variables in this chapter),
only numeric indexing is available: 

```
> lines_v[58]
[1] "# نعوذ بالله من عمل يقرب من سخطه، ونسأله التوفيق لما يدني من رضاه"
> lines_v["# نعوذ بالله من عمل يقرب من سخطه، ونسأله التوفيق لما يدني من رضاه"]
[1] NA
```

The output of our attempt to use named indexing on the `lines_v` vector is `NA`
(short for "Not Available"), an indicator for missing values. 

### Exercises

#### 1. Print the 5th most common token in al-Ṭabari's History and its frequency.
  
```{r ex="fifth", type="pre-exercise-code"}
if(! ("stringr" %in% (.packages()))) library("stringr")

if (! (exists("sorted_book_freqs_t"))) {
  # make sure Arabic is displayed correctly: 
  Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
    
  url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
  text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
  splitter_index <- which(text_v == "#META#Header#End#")
  lines_v <- text_v[(splitter_index+1):length(text_v)]
  book_v <- paste(lines_v, collapse = "\n")
  book_word_l <- str_split(book_v, "\\W+")
  book_word_v <- unlist(book_word_l)
  book_freqs_t <- table(book_word_v)
  sorted_book_freqs_t <- sort(book_freqs_t, decreasing = TRUE)
}

```
  
```{r ex = "fifth", type="sample-code" }
# Print 5th most common token: 
  
```
  
```{r ex = "fifth", type="hint" }
"Use numerical indexing with the `sorted_book_freqs_t` table" 
```
  
  
#### 2. Print the ten most common tokens in al-Ṭabari's History
  
```{r ex="ten", type="pre-exercise-code"}
if(! ("stringr" %in% (.packages()))) library("stringr")

if (! (exists("sorted_book_freqs_t"))) {
  # make sure Arabic is displayed correctly: 
  Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
  
  url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
  text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
  splitter_index <- which(text_v == "#META#Header#End#")
  lines_v <- text_v[(splitter_index+1):length(text_v)]
  book_v <- paste(lines_v, collapse = "\n")
  book_word_l <- str_split(book_v, "\\W+")
  book_word_v <- unlist(book_word_l)
  book_freqs_t <- table(book_word_v)
  sorted_book_freqs_t <- sort(book_freqs_t, decreasing = TRUE)
}
  
```
  
```{r ex = "ten", type="sample-code" }
# Print the 10 most common tokens and their frequencies: 
```
  
```{r ex = "ten", type="hint" }
"use the `:` operator to create a sequence of numbers." 
```
  
#### 3. Find the frequency of the token "الخليفة" in al-Ṭabari's Tarikh:
  
```{r ex="khalifa_freq", type="pre-exercise-code"}
if(! ("stringr" %in% (.packages()))) library("stringr")
  
if (! (exists("sorted_book_freqs_t"))) {
  # make sure Arabic is displayed correctly: 
  Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
  
  url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
  text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
  splitter_index <- which(text_v == "#META#Header#End#")
  lines_v <- text_v[(splitter_index+1):length(text_v)]
  book_v <- paste(lines_v, collapse = "\n")
  book_word_l <- str_split(book_v, "\\W+")
  book_word_v <- unlist(book_word_l)
  book_freqs_t <- table(book_word_v)
  sorted_book_freqs_t <- sort(book_freqs_t, decreasing = TRUE)
}
  
```
  
```{r ex = "khalifa_freq", type="sample-code" }
# Print the frequency of the token "al-khalifa": 
  
```
  
```{r ex = "khalifa_freq", type="hint" }
"use named indexing on the `sorted_book_freqs_t` table. Don't forget to use quotation marks between the brackets!" 
  
```
  
  
## Relative frequencies
  
Often, it is more useful to know how frequent a word is relative to the number of
words in a text than its absolute frequency (the number of times it is used in the
text). After all, the absolute frequencies of a word are dependent on how many 
words the text contains: if a word appears three times in a text of 25 words, 
that is entirely different from a word that appears three times in a million-word
text. 
  
In order to find the relative frequency of a word in a text, we divide the 
frequency of that word by the number of words in the text. 
  
In the previous chapter, we have already seen how you can find the number of tokens
in our text: we simply take the length (that is, the number of elements) of the
`book_word_v` vector: 
    
    
```{r ex="all_tokens", type="pre-exercise-code"}
if(! ("stringr" %in% (.packages()))) library("stringr")

if (! (exists("book_word_v"))) {
  # make sure Arabic is displayed correctly: 
  Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
  
  url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
  text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
  splitter_index <- which(text_v == "#META#Header#End#")
  lines_v <- text_v[(splitter_index+1):length(text_v)]
  book_v <- paste(lines_v, collapse = "\n")
  book_word_l <- str_split(book_v, "\\W+")
  book_word_v <- unlist(book_word_l)
}

```
  
```{r ex="all_tokens", type="sample-code"}
all_tokens <- length(book_word_v)
all_tokens
```
  
We can find the number of tokens in our text also by adding up all frequencies
in the `sorted_book_freqs_t` table:
    
```{r ex="all_token_freqs", type="pre-exercise-code"}
if(! ("stringr" %in% (.packages()))) library("stringr")

if (! (exists("sorted_book_freqs_t"))) {
  # make sure Arabic is displayed correctly: 
  Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
    
  url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
  text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
  splitter_index <- which(text_v == "#META#Header#End#")
  lines_v <- text_v[(splitter_index+1):length(text_v)]
  book_v <- paste(lines_v, collapse = "\n")
  book_word_l <- str_split(book_v, "\\W+")
  book_word_v <- unlist(book_word_l)
  book_freqs_t <- table(book_word_v)
  sorted_book_freqs_t <- sort(book_freqs_t, decreasing = TRUE)
}
  
if (! (exists("all_tokens"))) {
  all_tokens <- length(book_word_v)
}
```
  
```{r ex="all_token_freqs", type="sample-code"}
all_token_freqs <- sum(sorted_book_freqs_t)
all_token_freqs
all_token_freqs == all_tokens
```
  
Now we can calculate the relative frequency of the most common word in our table:
    
```{r ex="rel_freq_1", type="pre-exercise-code"}
if(! ("stringr" %in% (.packages()))) library("stringr")
  
if (! (exists("sorted_book_freqs_t"))) {
  # make sure Arabic is displayed correctly: 
  Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
  
  url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
  text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
  splitter_index <- which(text_v == "#META#Header#End#")
  lines_v <- text_v[(splitter_index+1):length(text_v)]
  book_v <- paste(lines_v, collapse = "\n")
  book_word_l <- str_split(book_v, "\\W+")
  book_word_v <- unlist(book_word_l)
  book_freqs_t <- table(book_word_v)
  sorted_book_freqs_t <- sort(book_freqs_t, decreasing = TRUE)
}
  
```
  
```{r ex="rel_freq_1", type="sample-code"}
all_token_freqs <- sum(sorted_book_freqs_t)
rel_freq <- sorted_book_freqs_t[1] / all_token_freqs
rel_freq
```
  
The output of the code shows that the token "ibn"  accounts for almost 3 percent 
of all tokens in al-Ṭabari's History; if the word would be evenly distributed
over the text, in every chunk of 100 words from the text, you could expect
about three times the word "ibn". The frequency of this word of course has to do
with the fact that "ibn" ("son") is an essential element in the Arabic name system.
Would the word also be the most common word in other types of texts than historical
texts? You could now go and find out...

### Exercises: 

#### 1. Find the relative frequency of the token "الخليفة" in al-Ṭabari's Tarikh:
    
```{r ex="khalifa_rel_freq", type="pre-exercise-code"}
if(! ("stringr" %in% (.packages()))) library("stringr")
  
if (! (exists("sorted_book_freqs_t"))) {
# make sure Arabic is displayed correctly: 
  Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
    
  url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
  text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
  splitter_index <- which(text_v == "#META#Header#End#")
  lines_v <- text_v[(splitter_index+1):length(text_v)]
  book_v <- paste(lines_v, collapse = "\n")
  book_word_l <- str_split(book_v, "\\W+")
  book_word_v <- unlist(book_word_l)
  book_freqs_t <- table(book_word_v)
  sorted_book_freqs_t <- sort(book_freqs_t, decreasing = TRUE)
}
  
```
  
```{r ex = "khalifa_rel_freq", type="sample-code" }
# Print the relative frequency of the token "al-khalifa": 
  
```
  
```{r ex = "khalifa_rel_freq", type="hint" }
"use named indexing on the `sorted_book_freqs_t` table. Don't forget to use quotation marks between the brackets!" 
  
```
  
  
## Recycling
  
If we want to calculate the percentages of a number of different tokens
(for example, the ten most frequent tokens in the text), 
we do not have to divide the absolute frequency of every token separately by the 
token count of the entire text: 
  
```{r ex="recycling_1", type="pre-exercise-code"}
if(! ("stringr" %in% (.packages()))) library("stringr")
  
if (! (exists("sorted_book_freqs_t"))) {
  # make sure Arabic is displayed correctly: 
  Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
  
  url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
  text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
  splitter_index <- which(text_v == "#META#Header#End#")
  lines_v <- text_v[(splitter_index+1):length(text_v)]
  book_v <- paste(lines_v, collapse = "\n")
  book_word_l <- str_split(book_v, "\\W+")
  book_word_v <- unlist(book_word_l)
  book_freqs_t <- table(book_word_v)
  sorted_book_freqs_t <- sort(book_freqs_t, decreasing = TRUE)
}
  
```
  
```{r ex="recycling_1", type="sample-code"}
all_token_freqs <- sum(sorted_book_freqs_t)

most_common <- sorted_book_freqs_t[1:10]
print("10 most common tokens")
most_common
class(most_common)

rel_freq <- most_common / all_token_freqs
print("relative frequencies:")
rel_freq
```
  
Let's break this code down: 

1. First we calculate the number of tokens in the text
2. Then, we use numerical indexing with a vector containing the numbers from 1 
to 10 to extract the ten most frequent words and their frequencies; and we assign
these to a variable named `most_common`. Calling the `class()` function on this
variable shows that it is a table, just like the `sorted_book_freqs_t` variable.
3. Finally, we divide this variable by the number of tokens in the text. 

R understands that we want to divide every value in the `most_common` table
by the `all_token_freqs` value. 

What is going on behind the scenes is that
`all_token_freqs` is a numerical vector with one element (you can check this by 
running the `mode()` and `length()` functions on `all_token_freqs`), while 
`most_common` is a table containing 10 elements. R can only apply an operation 
like division or multiplication with vectors/tables/... that have the same length. 
In order to carry out the operation anyway, it temporarily extends the shorter 
vector by **recycling** (repeating) the values of the shorter vector until
both vectors have the same length. 

We can illustrate the concept of recycling with a dummy example: 

```{r}
v <- c(2,2,2,2,2,2)
m <- c(1,2)
v * m


```

When multiplying data collections like vectors and tables, R will try to 
multiply the first element of the first collection with the first element 
of the second collection, the second element with the second, etc. 
It can only do that when both collection have the same length (that is, contain
the same number of elements). 
In our example, vector `m` has less elements than vector `v`, so R will start 
*recycling* the values of `m` until it has reached the same length as `v`: 
it basically turns the multiplication `c(2,2,2,2,2,2) * c(1,2)` into 
`c(2,2,2,2,2,2) * c(1,2,1,2,1,2)`. 

Going back to our calculation of the relative frequencies of the 10
most frequent tokens in the text, the one and only element of the 
`all_token_freqs` vector is recycled there for every value in the `most_common`
table. 

We can use the same concept to convert the relative frequency of multiple tokens 
into percentages. 

If we want to convert the relative frequency of one token into a percentage,
we have to multiply it by 100: 

```{r ex="rel_freq_2", type="pre-exercise-code"}
if(! ("stringr" %in% (.packages()))) library("stringr")

if (! (exists("sorted_book_freqs_t"))) {
  # make sure Arabic is displayed correctly: 
  Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
  
  url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
  text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
  splitter_index <- which(text_v == "#META#Header#End#")
  lines_v <- text_v[(splitter_index+1):length(text_v)]
  book_v <- paste(lines_v, collapse = "\n")
  book_word_l <- str_split(book_v, "\\W+")
  book_word_v <- unlist(book_word_l)
  book_freqs_t <- table(book_word_v)
  sorted_book_freqs_t <- sort(book_freqs_t, decreasing = TRUE)
}

```

```{r ex="rel_freq_2", type="sample-code"}
all_token_freqs <- sum(sorted_book_freqs_t)
rel_freq <- sorted_book_freqs_t[1] / all_token_freqs
print("relative frequency:")
rel_freq
perc <- 100 * rel_freq
print("relative frequency (percentage):")
perc
```

Try yourself to write the code that calculates the percentage for the 10 most
frequent tokens in the text: 

```{r ex="rel_freq_3", type="pre-exercise-code"}
if(! ("stringr" %in% (.packages()))) library("stringr")

if (! (exists("sorted_book_freqs_t"))) {
  # make sure Arabic is displayed correctly: 
  Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
  
  url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
  text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
  splitter_index <- which(text_v == "#META#Header#End#")
  lines_v <- text_v[(splitter_index+1):length(text_v)]
  book_v <- paste(lines_v, collapse = "\n")
  book_word_l <- str_split(book_v, "\\W+")
  book_word_v <- unlist(book_word_l)
  book_freqs_t <- table(book_word_v)
  sorted_book_freqs_t <- sort(book_freqs_t, decreasing = TRUE)
}

```

```{r ex="rel_freq_3", type="sample-code"}
# calculate the relative frequency (as a percentage) of the 10 most frequent tokens:

```

```{r ex="rel_freq_3", type="solution"}
# calculate the relative frequency (as a percentage) of the 10 most frequent tokens:
all_token_freqs <- sum(sorted_book_freqs_t)
rel_freq <- sorted_book_freqs_t[1:10] / all_token_freqs
print("relative frequency:")
rel_freq
perc <- 100 * rel_freq
print("relative frequency (percentage):")
perc
```


### Exercise


#### 1. Find out what happens when you multiply two vectors of different size, if the length of the longest one is not a multiple of the length of the shortest one:

```{r}
# create two numeric vectors, one with 5 elements and one with 3 elements
a <- 
b <- 
# try multiplying them. What happens?

```

#### 2. Find out whether recycling takes places with addition of vectors of different size as well: 

```{r}
# create two numeric vectors of different size 
a <- 
b <- 
# try adding them. What happens?

```


#### 3. Which percentage of al-Ṭabari's work consists of the twenty most common words?
  
  ```{r ex="cumul_freq", type="pre-exercise-code"}
if(! ("stringr" %in% (.packages()))) library("stringr")

if (! (exists("sorted_book_freqs_t"))) {
  # make sure Arabic is displayed correctly: 
  Sys.setlocale(category = "LC_ALL", locale = "C.UTF-8")
  
  url <- "https://raw.githubusercontent.com/OpenITI/0325AH/master/data/0310Tabari/0310Tabari.Tarikh/0310Tabari.Tarikh.Shamela0009783BK1-ara1.completed"
  text_v <- scan(url, what="character", sep="\n", encoding="UTF-8")
  splitter_index <- which(text_v == "#META#Header#End#")
  lines_v <- text_v[(splitter_index+1):length(text_v)]
  book_v <- paste(lines_v, collapse = "\n")
  book_word_l <- str_split(book_v, "\\W+")
  book_word_v <- unlist(book_word_l)
  book_freqs_t <- table(book_word_v)
  sorted_book_freqs_t <- sort(book_freqs_t, decreasing = TRUE)
}

```

```{r ex = "cumul_freq", type="sample-code" }
# Print the cumulative relative frequencies of the 20 most common words in the text: 

```

```{r ex = "cumul_freq", type="hint" }
"use the `sum()` function to calculate the sum of the frequencies of the 20 most common words" 

```



